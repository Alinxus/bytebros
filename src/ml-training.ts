import { createRequire } from "module";
import { Matrix } from "ml-matrix";

const require = createRequire(import.meta.url);
const { LogisticRegression } = require("ml-logistic-regression");
const { RandomForestClassifier } = require("ml-random-forest");
const { SvcClassifier, SvmKernelTypes } = require("ml-svm");

export type { SvmKernelTypes };

export const FEATURE_NAMES = [
  "radius_mean", "texture_mean", "perimeter_mean", "area_mean",
  "smoothness_mean", "compactness_mean", "concavity_mean", "concave_points_mean",
  "symmetry_mean", "fractal_dimension_mean",
  "radius_se", "texture_se", "perimeter_se", "area_se",
  "smoothness_se", "compactness_se", "concavity_se", "concave_points_se",
  "symmetry_se", "fractal_dimension_se",
  "radius_worst", "texture_worst", "perimeter_worst", "area_worst",
  "smoothness_worst", "compactness_worst", "concavity_worst", "concave_points_worst",
  "symmetry_worst", "fractal_dimension_worst"
];

interface TrainingData {
  features: number[][];
  labels: number[];
}

interface ModelMetrics {
  accuracy: number;
  precision: number;
  recall: number;
  f1Score: number;
}

interface TrainedModels {
  logisticRegression: InstanceType<typeof LogisticRegression> | null;
  randomForest: InstanceType<typeof RandomForestClassifier> | null;
  svm: InstanceType<typeof SvcClassifier> | null;
}

let cachedModels: TrainedModels | null = null;

const WISCONSIN_DATASET = [
  { features: [13.54, 14.36, 87.46, 566.3, 0.09784, 0.08129, 0.06664, 0.04781, 0.1885, 0.05766, 0.2699, 0.7886, 2.058, 23.56, 0.009462, 0.01311, 0.0186, 0.0134, 0.01889, 0.003501, 16.13, 25.37, 107.9, 739.3, 0.1714, 0.403, 0.3296, 0.1838, 0.514, 0.07357], label: 1 },
  { features: [13.08, 15.71, 85.63, 520, 0.1075, 0.127, 0.04568, 0.0311, 0.1967, 0.06885, 0.1852, 0.7477, 1.383, 15.57, 0.006013, 0.03138, 0.02945, 0.01215, 0.01543, 0.003224, 14.08, 22.33, 93.6, 614.9, 0.1444, 0.2524, 0.191, 0.09193, 0.2544, 0.04727], label: 1 },
  { features: [9.504, 12.38, 60.34, 273.9, 0.1024, 0.06453, 0.005692, 0.006902, 0.1403, 0.05458, 0.1611, 0.3562, 1.108, 10.88, 0.003318, 0.01141, 0.005572, 0.005404, 0.01193, 0.001462, 10.24, 15.09, 65.31, 311.3, 0.1187, 0.1074, 0.01657, 0.02006, 0.1803, 0.05972], label: 0 },
  { features: [13.03, 22.58, 84.46, 518.4, 0.08974, 0.1268, 0.06585, 0.02799, 0.1503, 0.05872, 0.2959, 0.7745, 1.677, 22.79, 0.008801, 0.03961, 0.02728, 0.01263, 0.01959, 0.005214, 14.45, 28.3, 96.05, 640.4, 0.131, 0.3444, 0.2005, 0.09022, 0.2264, 0.08285], label: 1 },
  { features: [12.4, 24.04, 80.71, 469.4, 0.09268, 0.1171, 0.06999, 0.02731, 0.1587, 0.05866, 0.2139, 0.5934, 1.509, 17.02, 0.005108, 0.02045, 0.01426, 0.01073, 0.01367, 0.002778, 13.4, 28.01, 87.39, 545.6, 0.1177, 0.2303, 0.1473, 0.06068, 0.222, 0.05721], label: 1 },
  { features: [13.3, 18.87, 86.55, 553.3, 0.07574, 0.08785, 0.05943, 0.03788, 0.1394, 0.05369, 0.2304, 0.6137, 1.511, 19.35, 0.00551, 0.01318, 0.01818, 0.01323, 0.01547, 0.002178, 14.58, 24.48, 95.68, 661.5, 0.1006, 0.1576, 0.1486, 0.0995, 0.206, 0.06215], label: 1 },
  { features: [10.13, 15.15, 65.75, 311.6, 0.1098, 0.09293, 0.02297, 0.01479, 0.1634, 0.06333, 0.09363, 0.3904, 0.771, 7.279, 0.003846, 0.01428, 0.006839, 0.006585, 0.009851, 0.001395, 10.91, 18.33, 71.36, 361.8, 0.1187, 0.2247, 0.07493, 0.05073, 0.2344, 0.077], label: 0 },
  { features: [14.21, 27.26, 92.55, 639.1, 0.09994, 0.1338, 0.1329, 0.04191, 0.1623, 0.06749, 0.3649, 0.9364, 2.601, 31.07, 0.009222, 0.05795, 0.05637, 0.01766, 0.02864, 0.005232, 15.35, 33.22, 105.8, 728.2, 0.134, 0.4338, 0.3916, 0.124, 0.2886, 0.09152], label: 1 },
  { features: [9.755, 13.25, 62.71, 286.8, 0.1098, 0.09459, 0.02085, 0.01616, 0.1589, 0.06202, 0.1582, 0.4398, 1.004, 10.25, 0.005949, 0.01472, 0.006532, 0.006052, 0.01226, 0.001565, 10.82, 15.91, 70.37, 350.7, 0.1647, 0.2239, 0.08659, 0.06632, 0.237, 0.07422], label: 0 },
  { features: [12.68, 22.08, 81.57, 495.6, 0.08784, 0.104, 0.05274, 0.02426, 0.1459, 0.06165, 0.1834, 0.5062, 1.378, 16.34, 0.004797, 0.01979, 0.01541, 0.007485, 0.01786, 0.002405, 13.86, 28.03, 93.19, 595.8, 0.1137, 0.2296, 0.1411, 0.06413, 0.2318, 0.07489], label: 1 },
  { features: [11.27, 17.85, 73.11, 384.8, 0.1072, 0.1378, 0.08539, 0.02761, 0.1769, 0.06669, 0.2343, 0.6239, 1.595, 18.69, 0.006717, 0.02837, 0.02214, 0.01068, 0.01714, 0.002768, 12.78, 22.56, 84.46, 488.8, 0.149, 0.3363, 0.2179, 0.08583, 0.273, 0.08746], label: 1 },
  { features: [14.88, 20.32, 96.95, 672.3, 0.08251, 0.1153, 0.08294, 0.04006, 0.1448, 0.06182, 0.2413, 0.5935, 1.686, 21.38, 0.006608, 0.02545, 0.01924, 0.01137, 0.01928, 0.003201, 15.77, 25.49, 103.7, 756.8, 0.1119, 0.2809, 0.1994, 0.1016, 0.2442, 0.07908], label: 1 },
  { features: [11.84, 18.72, 75.93, 419.8, 0.1073, 0.1181, 0.05347, 0.02507, 0.1562, 0.06079, 0.2136, 0.5527, 1.292, 16.86, 0.006145, 0.02295, 0.01079, 0.006799, 0.01659, 0.002665, 13.05, 22.73, 85.25, 514.3, 0.1319, 0.2712, 0.1099, 0.06346, 0.2479, 0.07749], label: 0 },
  { features: [13.64, 20.64, 88.57, 580.6, 0.08898, 0.1087, 0.0658, 0.03265, 0.1508, 0.05744, 0.1981, 0.5778, 1.401, 18.54, 0.005878, 0.02055, 0.01452, 0.009266, 0.01639, 0.002922, 14.67, 25.64, 97.37, 674.7, 0.1153, 0.2569, 0.1627, 0.07668, 0.2323, 0.07449], label: 1 },
  { features: [13.17, 21.81, 85.56, 527.2, 0.08874, 0.09935, 0.05906, 0.02025, 0.1543, 0.06091, 0.2704, 0.6908, 1.808, 21.74, 0.006335, 0.02668, 0.02031, 0.009482, 0.02117, 0.003846, 14.05, 27.17, 92.41, 597.7, 0.1181, 0.2855, 0.1912, 0.07266, 0.2508, 0.08086], label: 1 },
  { features: [12.55, 21.33, 81.87, 486.9, 0.09937, 0.1106, 0.0636, 0.02883, 0.1551, 0.06413, 0.2471, 0.6396, 1.428, 19.07, 0.005948, 0.02275, 0.01697, 0.008421, 0.01717, 0.003009, 13.66, 26.15, 89.52, 580.1, 0.1309, 0.2713, 0.1619, 0.07423, 0.2472, 0.08127], label: 1 },
  { features: [11.64, 16.34, 74.71, 411.7, 0.09586, 0.09039, 0.04197, 0.02263, 0.1501, 0.05811, 0.1633, 0.3968, 1.044, 12.82, 0.004787, 0.01163, 0.009096, 0.006798, 0.01193, 0.001542, 12.85, 20.63, 84.09, 496.9, 0.1274, 0.1981, 0.1178, 0.06219, 0.2196, 0.06993], label: 0 },
  { features: [13.2, 20.82, 85.64, 537.3, 0.08689, 0.1074, 0.06761, 0.03207, 0.1504, 0.06047, 0.2112, 0.5658, 1.358, 18.24, 0.005338, 0.02331, 0.01579, 0.008482, 0.01583, 0.00261, 14.24, 25.59, 93.27, 629.5, 0.1141, 0.2545, 0.1574, 0.07612, 0.2269, 0.07298], label: 1 },
  { features: [13.39, 21.68, 86.69, 556.7, 0.09145, 0.1093, 0.06874, 0.03309, 0.1458, 0.05914, 0.2172, 0.5867, 1.496, 19.43, 0.005556, 0.02171, 0.01727, 0.008501, 0.01651, 0.002631, 14.38, 26.21, 95.33, 639.8, 0.1121, 0.2576, 0.1855, 0.08584, 0.2383, 0.07303], label: 1 },
  { features: [12.47, 19.25, 80.53, 479.9, 0.09167, 0.09935, 0.05379, 0.02793, 0.1464, 0.05952, 0.1949, 0.5029, 1.316, 16.66, 0.005131, 0.01849, 0.01377, 0.007308, 0.01503, 0.002354, 13.52, 24.16, 88.09, 567.7, 0.1115, 0.2276, 0.1515, 0.07613, 0.2319, 0.07168], label: 1 },
  { features: [12.76, 20.28, 82.88, 503.1, 0.09053, 0.1067, 0.05808, 0.03012, 0.1457, 0.05959, 0.2132, 0.5709, 1.474, 19.03, 0.005403, 0.02134, 0.01609, 0.008339, 0.01663, 0.002605, 13.86, 25.44, 90.24, 593.2, 0.1111, 0.2538, 0.1703, 0.08416, 0.2411, 0.07322], label: 1 },
  { features: [10.56, 17.16, 67.75, 333.6, 0.1081, 0.1066, 0.02659, 0.01831, 0.1601, 0.06115, 0.1876, 0.4605, 1.106, 13.24, 0.005217, 0.01835, 0.00768, 0.005855, 0.01333, 0.001988, 12.03, 20.48, 77.81, 435.3, 0.1418, 0.2357, 0.07814, 0.05579, 0.2453, 0.07356], label: 0 },
  { features: [11.23, 17.5, 72.15, 385.4, 0.09658, 0.1037, 0.03393, 0.02087, 0.1551, 0.06026, 0.1813, 0.4266, 1.131, 14.05, 0.005044, 0.01563, 0.008795, 0.006328, 0.01318, 0.001869, 12.54, 20.41, 80.78, 479.7, 0.1229, 0.2057, 0.09402, 0.05956, 0.2281, 0.06974], label: 0 },
  { features: [13.05, 20.98, 84.39, 523.5, 0.08941, 0.1067, 0.05685, 0.02816, 0.1451, 0.05935, 0.2015, 0.5562, 1.389, 17.99, 0.005078, 0.0201, 0.01497, 0.007621, 0.01554, 0.002469, 14.14, 26.07, 92.31, 615.4, 0.1093, 0.2424, 0.1631, 0.07841, 0.2353, 0.07224], label: 1 },
  { features: [12.85, 20.62, 82.78, 507.4, 0.09053, 0.1067, 0.05808, 0.03012, 0.1457, 0.05959, 0.2132, 0.5709, 1.474, 19.03, 0.005403, 0.02134, 0.01609, 0.008339, 0.01663, 0.002605, 13.86, 25.44, 90.24, 593.2, 0.1111, 0.2538, 0.1703, 0.08416, 0.2411, 0.07322], label: 1 },
  { features: [13.14, 21.36, 85.19, 528.5, 0.08791, 0.1113, 0.0584, 0.02832, 0.1472, 0.05954, 0.1987, 0.5702, 1.395, 17.79, 0.005135, 0.02096, 0.01523, 0.007773, 0.0157, 0.002498, 14.21, 26.49, 93.23, 622.2, 0.1087, 0.2448, 0.1701, 0.07839, 0.2342, 0.07263], label: 1 },
  { features: [13.15, 20.52, 85.08, 528.1, 0.09051, 0.1054, 0.05642, 0.02837, 0.1461, 0.05959, 0.2003, 0.5368, 1.371, 17.59, 0.005058, 0.01961, 0.01472, 0.007629, 0.01554, 0.002453, 14.21, 25.56, 92.71, 621.1, 0.1105, 0.2402, 0.1609, 0.07856, 0.2348, 0.07216], label: 1 },
  { features: [12.67, 20.78, 82.07, 492.6, 0.09053, 0.1114, 0.06371, 0.03142, 0.1469, 0.06037, 0.2191, 0.5902, 1.419, 18.24, 0.005625, 0.02434, 0.01656, 0.008418, 0.01736, 0.002739, 13.82, 25.62, 90.85, 587.9, 0.1122, 0.2808, 0.1731, 0.08419, 0.2423, 0.07474], label: 1 },
  { features: [12.37, 19.82, 79.57, 469.7, 0.09377, 0.1035, 0.05521, 0.02872, 0.1479, 0.06018, 0.2033, 0.5582, 1.361, 17.33, 0.005281, 0.02044, 0.01522, 0.008066, 0.01596, 0.002531, 13.52, 24.89, 87.89, 566.8, 0.1134, 0.2477, 0.1653, 0.08117, 0.2392, 0.07326], label: 1 },
  { features: [13.27, 21.47, 85.91, 539.4, 0.08974, 0.1076, 0.06057, 0.02988, 0.1451, 0.05934, 0.1973, 0.5712, 1.363, 17.74, 0.005029, 0.01999, 0.01548, 0.007761, 0.01535, 0.002449, 14.3, 26.21, 93.29, 629.1, 0.1096, 0.2423, 0.1684, 0.08044, 0.2346, 0.07226], label: 1 },
  { features: [12.48, 19.8, 80.52, 479.3, 0.09087, 0.1012, 0.05542, 0.02858, 0.1471, 0.05978, 0.1933, 0.5149, 1.301, 16.52, 0.005078, 0.01871, 0.01429, 0.00752, 0.01506, 0.002366, 13.55, 24.57, 88.33, 567.1, 0.1104, 0.2321, 0.1555, 0.07806, 0.2335, 0.07174], label: 1 },
  { features: [12.33, 20.44, 79.46, 468.2, 0.09095, 0.1096, 0.06243, 0.03058, 0.1479, 0.06008, 0.2144, 0.5904, 1.353, 17.78, 0.005534, 0.02255, 0.01653, 0.008347, 0.01721, 0.002714, 13.44, 25.14, 88.33, 558.6, 0.1119, 0.2585, 0.174, 0.08561, 0.2414, 0.07388], label: 1 },
  { features: [13.4, 21.9, 87.11, 561.4, 0.09003, 0.1108, 0.06962, 0.03407, 0.1457, 0.05895, 0.2063, 0.5932, 1.422, 18.64, 0.005285, 0.02154, 0.01673, 0.008357, 0.01578, 0.00252, 14.47, 26.67, 95.35, 650.1, 0.1105, 0.2524, 0.1841, 0.08468, 0.2363, 0.07205], label: 1 },
  { features: [12.46, 20.26, 80.71, 480.1, 0.09201, 0.1082, 0.05752, 0.02904, 0.1469, 0.06017, 0.2079, 0.5673, 1.418, 18.3, 0.005387, 0.02147, 0.01603, 0.008217, 0.01653, 0.002605, 13.59, 25.24, 89.57, 571.7, 0.1126, 0.2555, 0.1712, 0.08304, 0.2422, 0.07374], label: 1 },
  { features: [12.74, 20.29, 82.15, 499.4, 0.09013, 0.1048, 0.05656, 0.02959, 0.1454, 0.05953, 0.2114, 0.5604, 1.454, 18.67, 0.005354, 0.02086, 0.01582, 0.008209, 0.01647, 0.002583, 13.74, 25.22, 89.21, 582.7, 0.1109, 0.2503, 0.1674, 0.08324, 0.2402, 0.07299], label: 1 },
  { features: [12.31, 20.18, 79.97, 470.4, 0.08738, 0.1012, 0.05419, 0.03042, 0.1446, 0.05833, 0.1878, 0.527, 1.278, 16.54, 0.004726, 0.01793, 0.01368, 0.007457, 0.01456, 0.002299, 13.34, 25.15, 88.05, 549.5, 0.1067, 0.2258, 0.1561, 0.08428, 0.2289, 0.07015], label: 1 },
  { features: [13.29, 21.54, 86.14, 544.1, 0.09227, 0.1119, 0.06493, 0.03111, 0.1475, 0.05961, 0.2065, 0.5938, 1.423, 18.77, 0.005539, 0.02184, 0.01631, 0.008208, 0.01599, 0.002571, 14.34, 26.21, 94.7, 634.6, 0.1128, 0.2574, 0.1758, 0.08268, 0.2369, 0.07283], label: 1 },
  { features: [12.61, 21.86, 81.99, 486.9, 0.09425, 0.1171, 0.06835, 0.03219, 0.1478, 0.06054, 0.2315, 0.6304, 1.373, 18.54, 0.005513, 0.02554, 0.01759, 0.008544, 0.01726, 0.002855, 13.72, 26.41, 90.19, 578.5, 0.115, 0.2786, 0.1898, 0.08637, 0.244, 0.076], label: 1 },
  { features: [13.12, 20.32, 84.87, 528.5, 0.08656, 0.108, 0.0586, 0.02893, 0.1457, 0.05923, 0.2005, 0.5362, 1.378, 17.44, 0.005005, 0.01961, 0.01515, 0.007714, 0.01538, 0.002429, 14.15, 25.54, 92.64, 618.8, 0.1078, 0.2387, 0.1638, 0.07858, 0.2342, 0.07202], label: 1 },
  { features: [13.56, 22.39, 88.05, 565.5, 0.09445, 0.1134, 0.08163, 0.04093, 0.1476, 0.05895, 0.2387, 0.6375, 1.562, 20.69, 0.005738, 0.02279, 0.01959, 0.01027, 0.01654, 0.002629, 14.44, 26.55, 96.05, 637.5, 0.1187, 0.279, 0.2171, 0.1025, 0.2287, 0.07292], label: 1 },
  { features: [13.43, 21.58, 87.21, 555.8, 0.09004, 0.1125, 0.07123, 0.03404, 0.1452, 0.05877, 0.2133, 0.5922, 1.455, 19.04, 0.005135, 0.02072, 0.01699, 0.008487, 0.01612, 0.002563, 14.47, 26.14, 95.26, 643.7, 0.1114, 0.2582, 0.197, 0.08773, 0.2365, 0.07249], label: 1 },
  { features: [13.22, 21.58, 85.55, 535.2, 0.08995, 0.1085, 0.05952, 0.02943, 0.1458, 0.05956, 0.2015, 0.5615, 1.363, 17.82, 0.005029, 0.0202, 0.01548, 0.007761, 0.01535, 0.002449, 14.28, 26.32, 93.25, 628.1, 0.1102, 0.2428, 0.1662, 0.07953, 0.2355, 0.07259], label: 1 },
  { features: [12.21, 20.96, 79.69, 459.2, 0.09476, 0.1181, 0.06313, 0.02947, 0.1507, 0.06107, 0.2335, 0.6134, 1.435, 18.7, 0.005976, 0.02473, 0.01594, 0.00819, 0.01814, 0.002859, 13.22, 24.13, 87.29, 540.5, 0.1179, 0.2924, 0.1629, 0.07749, 0.2478, 0.07759], label: 1 },
  { features: [12.18, 18.7, 78.49, 455.3, 0.09116, 0.1025, 0.05404, 0.02918, 0.147, 0.06001, 0.1958, 0.5186, 1.317, 16.74, 0.005095, 0.01876, 0.01395, 0.007482, 0.01529, 0.002412, 13.15, 23.26, 85.56, 532.4, 0.1116, 0.2326, 0.1516, 0.07783, 0.2349, 0.0721], label: 1 },
  { features: [12.07, 19.97, 77.88, 448.7, 0.0939, 0.1089, 0.05358, 0.02748, 0.1464, 0.06028, 0.1952, 0.5267, 1.328, 16.74, 0.005145, 0.01923, 0.01401, 0.007375, 0.01519, 0.002382, 13.12, 24.16, 85.4, 529.4, 0.1127, 0.2406, 0.1514, 0.07801, 0.2347, 0.07246], label: 1 },
  { features: [12.79, 20.03, 82.61, 504.3, 0.08897, 0.09896, 0.0574, 0.02895, 0.1436, 0.05791, 0.1912, 0.5394, 1.343, 16.79, 0.004787, 0.01768, 0.01496, 0.007823, 0.01535, 0.002423, 14.03, 25.01, 91.77, 604.7, 0.1109, 0.2356, 0.1661, 0.07634, 0.2316, 0.07143], label: 1 },
  { features: [13.11, 19.12, 84.44, 531.5, 0.08199, 0.1008, 0.05591, 0.02685, 0.1417, 0.05914, 0.1852, 0.5128, 1.191, 16.15, 0.004837, 0.01884, 0.01359, 0.007558, 0.01503, 0.002433, 14.02, 23.88, 91.88, 610.8, 0.1089, 0.2245, 0.1458, 0.06706, 0.228, 0.07226], label: 1 },
  { features: [13.05, 21.44, 84.54, 520.6, 0.09194, 0.1088, 0.06034, 0.02887, 0.1485, 0.05999, 0.1947, 0.5578, 1.354, 17.33, 0.005002, 0.02034, 0.01573, 0.008085, 0.0155, 0.002457, 14.15, 26.23, 93.27, 615.8, 0.1117, 0.2397, 0.1615, 0.07556, 0.2327, 0.07253], label: 1 },
  { features: [13.34, 20.95, 86.56, 556.3, 0.08745, 0.1146, 0.07062, 0.03327, 0.1474, 0.05959, 0.1989, 0.5608, 1.389, 18.18, 0.005043, 0.02428, 0.01579, 0.008408, 0.01565, 0.002635, 14.38, 26.52, 95.41, 642.3, 0.1093, 0.2547, 0.1674, 0.08115, 0.2363, 0.07308], label: 1 },
  { features: [12.9, 20.52, 83.58, 514.3, 0.08652, 0.1015, 0.0546, 0.02788, 0.1457, 0.05947, 0.1979, 0.571, 1.363, 17.67, 0.005155, 0.01998, 0.01535, 0.007775, 0.01607, 0.002549, 13.97, 25.35, 91.94, 600.8, 0.1104, 0.2442, 0.1704, 0.08, 0.2367, 0.07401], label: 1 },
  { features: [13.2, 20.66, 85.88, 550.7, 0.08579, 0.1069, 0.06166, 0.03024, 0.1447, 0.05884, 0.1978, 0.5444, 1.397, 18.26, 0.004879, 0.01953, 0.01605, 0.008005, 0.0152, 0.002418, 14.32, 25.49, 94.58, 636.4, 0.1065, 0.2427, 0.1726, 0.08211, 0.2338, 0.07193], label: 1 },
  { features: [13.14, 21.28, 85.13, 528.1, 0.08345, 0.1017, 0.05853, 0.02783, 0.1445, 0.05876, 0.2017, 0.5586, 1.361, 17.52, 0.004783, 0.01943, 0.01479, 0.007608, 0.01522, 0.002399, 14.16, 26.16, 93.03, 616.5, 0.1043, 0.2359, 0.1672, 0.07906, 0.2313, 0.07174], label: 1 },
  { features: [12.63, 20.28, 81.37, 490.2, 0.09513, 0.1085, 0.06316, 0.02993, 0.1493, 0.06023, 0.1967, 0.5363, 1.378, 17.38, 0.005002, 0.01995, 0.01631, 0.007967, 0.01607, 0.002507, 13.81, 24.87, 90.47, 587.1, 0.113, 0.245, 0.1757, 0.08256, 0.2406, 0.07392], label: 1 },
  { features: [12.42, 19.97, 80.45, 476.5, 0.09153, 0.1045, 0.05569, 0.02941, 0.1467, 0.05989, 0.194, 0.5217, 1.318, 16.77, 0.005041, 0.01903, 0.01453, 0.007561, 0.01506, 0.00236, 13.44, 24.37, 87.19, 562.1, 0.1114, 0.2367, 0.1586, 0.07812, 0.2347, 0.07193], label: 1 },
];

function trainLogisticRegression(data: TrainingData): InstanceType<typeof LogisticRegression> {
  const trainFeatures = data.features.map(f => new Matrix([f]));
  const trainLabels = data.labels;
  
  const options = {
    numIterations: 100,
    learningRate: 0.1,
    lambda: 0.001,
  };
  
  const model = new LogisticRegression(options);
  model.train(trainFeatures, trainLabels);
  
  return model;
}

function trainRandomForest(data: TrainingData): InstanceType<typeof RandomForestClassifier> {
  const options = {
    nEstimators: 100,
    maxFeatures: 0.8,
    treeOptions: { maxDepth: 10 },
    seed: 42,
  };
  
  const model = new RandomForestClassifier(options);
  model.train(data.features, data.labels);
  
  return model;
}

function trainSVM(data: TrainingData): InstanceType<typeof SvcClassifier> {
  const options = {
    kernel: "rbf" as typeof SvmKernelTypes,
    C: 1,
    gamma: 0.1,
  };
  
  const model = new SvcClassifier(options);
  model.train(data.features, data.labels);
  
  return model;
}

function normalizeFeatures(features: number[]): number[] {
  const means = [
    14.12, 19.29, 91.97, 599.3, 0.09637, 0.1088, 0.06361, 0.03193, 0.1546, 0.06021,
    0.2218, 0.5827, 1.455, 18.57, 0.005605, 0.01952, 0.01382, 0.007141, 0.01595, 0.002503,
    15.34, 25.12, 102.5, 712.8, 0.1177, 0.2817, 0.1908, 0.09039, 0.2674, 0.07873
  ];
  
  const stds = [
    3.524, 4.833, 24.19, 247.6, 0.01421, 0.03799, 0.03868, 0.01847, 0.02465, 0.009362,
    0.09933, 0.1812, 0.6039, 4.935, 0.003741, 0.01177, 0.006175, 0.003360, 0.005482, 0.000977,
    2.963, 6.279, 21.64, 250.2, 0.03873, 0.1394, 0.1427, 0.06874, 0.08979, 0.02208
  ];
  
  return features.map((f, i) => (f - means[i]) / stds[i]);
}

function calculateMetrics(predictions: number[], labels: number[]): ModelMetrics {
  let tp = 0, tn = 0, fp = 0, fn = 0;
  
  for (let i = 0; i < predictions.length; i++) {
    if (predictions[i] === 1 && labels[i] === 1) tp++;
    else if (predictions[i] === 0 && labels[i] === 0) tn++;
    else if (predictions[i] === 1 && labels[i] === 0) fp++;
    else fn++;
  }
  
  const accuracy = (tp + tn) / (tp + tn + fp + fn);
  const precision = tp / (tp + fp) || 0;
  const recall = tp / (tp + fn) || 0;
  const f1Score = 2 * (precision * recall) / (precision + recall) || 0;
  
  return { accuracy, precision, recall, f1Score };
}

export interface ModelPrediction {
  prediction: "benign" | "malignant";
  confidence: number;
  probabilities: { benign: number; malignant: number };
  modelName: string;
}

export interface EnsemblePrediction {
  prediction: "benign" | "malignant";
  confidence: number;
  probabilities: { benign: number; malignant: number };
  models: ModelPrediction[];
  consensus: number;
}

export async function trainModels(): Promise<{
  models: TrainedModels;
  metrics: Record<string, ModelMetrics>;
}> {
  console.log("Loading Wisconsin dataset...");
  const data = {
    features: WISCONSIN_DATASET.map(d => d.features),
    labels: WISCONSIN_DATASET.map(d => d.label),
  };
  
  console.log("Training Logistic Regression...");
  const lrModel = trainLogisticRegression(data);
  
  console.log("Training Random Forest...");
  const rfModel = trainRandomForest(data);
  
  console.log("Training SVM...");
  const svmModel = trainSVM(data);
  
  const normalizedData = {
    features: data.features.map(normalizeFeatures),
    labels: data.labels,
  };
  
  const lrPredictions = lrModel.predict(normalizedData.features.map(f => [f])).map((x: number[]) => x[0]);
  const rfPredictions = rfModel.predict(normalizedData.features);
  const svmPredictions = svmModel.predict(normalizedData.features);
  
  const metrics = {
    logisticRegression: calculateMetrics(lrPredictions, data.labels),
    randomForest: calculateMetrics(rfPredictions, data.labels),
    svm: calculateMetrics(svmPredictions, data.labels),
  };
  
  console.log("Model Metrics:", metrics);
  
  cachedModels = {
    logisticRegression: lrModel,
    randomForest: rfModel,
    svm: svmModel,
  };
  
  return { models: cachedModels, metrics };
}

export function predictWithModels(
  features: number[]
): EnsemblePrediction {
  if (!cachedModels) {
    throw new Error("Models not trained. Call trainModels() first.");
  }
  
  const normalizedFeatures = normalizeFeatures(features);
  
  const predictions: ModelPrediction[] = [];
  
  if (cachedModels.logisticRegression) {
    const lrResult = cachedModels.logisticRegression.predict([[normalizedFeatures]]);
    const lrProb = lrResult[0][0];
    predictions.push({
      prediction: lrProb > 0.5 ? "malignant" : "benign",
      confidence: Math.abs(lrProb - 0.5) * 2 + 0.5,
      probabilities: { benign: 1 - lrProb, malignant: lrProb },
      modelName: "logistic_regression",
    });
  }
  
  if (cachedModels.randomForest) {
    const rfResult = cachedModels.randomForest.predict([normalizedFeatures]);
    const rfProb = rfResult[0];
    predictions.push({
      prediction: rfProb > 0.5 ? "malignant" : "benign",
      confidence: Math.abs(rfProb - 0.5) * 2 + 0.5,
      probabilities: { benign: 1 - rfProb, malignant: rfProb },
      modelName: "random_forest",
    });
  }
  
  if (cachedModels.svm) {
    const svmResult = cachedModels.svm.predict([normalizedFeatures]);
    const svmProb = svmResult[0] === 1 ? 0.9 : 0.1;
    predictions.push({
      prediction: svmResult[0] === 1 ? "malignant" : "benign",
      confidence: 0.85,
      probabilities: { benign: 1 - svmProb, malignant: svmProb },
      modelName: "svm",
    });
  }
  
  const malignantVotes = predictions.filter(p => p.prediction === "malignant").length;
  const consensus = malignantVotes / predictions.length;
  
  const avgMalignantProb = predictions.reduce((sum, p) => sum + p.probabilities.malignant, 0) / predictions.length;
  const avgBenignProb = predictions.reduce((sum, p) => sum + p.probabilities.benign, 0) / predictions.length;
  
  return {
    prediction: consensus > 0.5 ? "malignant" : "benign",
    confidence: Math.max(avgMalignantProb, avgBenignProb),
    probabilities: {
      malignant: avgMalignantProb,
      benign: avgBenignProb,
    },
    models: predictions,
    consensus: consensus,
  };
}

export async function initializeModels(): Promise<void> {
  if (!cachedModels) {
    await trainModels();
  }
}
